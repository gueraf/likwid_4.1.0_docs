<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>LIKWID: &lt;CODE&gt;likwid-mpirun&lt;/CODE&gt;</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="logo.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">LIKWID
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title"><code>likwid-mpirun</code> </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1>Information</h1>
<p><code>likwid-mpirun</code> A tool to start and monitor MPI applications with LIKWID. It can be used as supplement of the MPI implementations' startup programm like <code>mpirun</code> or <code>mpiexec</code> with some enhancements for pinning of OpenMP thread in hybrid jobs. Moreover, <code>likwid-mpirun</code> can insert calls to <a class="el" href="likwid-perfctr.html"><code>likwid-perfctr</code></a> to measure hardware performance counters for each MPI process and its threads, including Marker API. Since the <a href="http://modules.sourceforge.net/">modules</a> system is widely used on clustered systems, <code>likwid-mpirun</code> checks the modules system to get MPI and OpenMP types. The hostfile must be in the format of the loaded MPI implementation.</p>
<h1>Options</h1>
<table class="doxtable">
<tr>
<th>Option </th><th>Description  </th></tr>
<tr>
<td>-h, &ndash;help </td><td>Print help message  </td></tr>
<tr>
<td>-v, &ndash;version </td><td>Print version information  </td></tr>
<tr>
<td>-d, &ndash;debug </td><td>Print debug information  </td></tr>
<tr>
<td>-n, -np, &ndash;n, &ndash;np &lt;arg&gt; </td><td>Specify the number of processes for MPI  </td></tr>
<tr>
<td>&ndash;nperdomain &lt;domain&gt;:&lt;arg&gt; </td><td>Schedule &lt;arg&gt; MPI processes for each affinity domain starting with &lt;domain&gt;, e.g S:2 translates in two MPI processes per socket.<br />
<code>likwid-mpirun</code> assumes that all participating hosts have the same topology.  </td></tr>
<tr>
<td>&ndash;hostfile &lt;file&gt; </td><td>Specify the file that should be used as hostfile.<br />
If not set, <code>likwid-mpirun</code> checks the <code>PBS_NODEFILE</code>, <code>LOADL_HOSTFILE</code> and <code>SLURM_HOSTFILE</code> environment variable  </td></tr>
<tr>
<td>&ndash;pin &lt;expr&gt; </td><td>For hybrid pinning specify the thread pinning expression for each MPI process.<br />
The format is similar to <a class="el" href="likwid-pin.html#CPU_expressions">CPU_expressions</a> separated by '_' for multiple processes.<br />
If -np is not set, the number of MPI processes is calculated using the pinning expressions.  </td></tr>
<tr>
<td>-s, &ndash;skip &lt;arg&gt; </td><td>'arg' must be a bitmask in hex. Threads with the ID equal to a set bit in bitmask will be skipped during pinning<br />
Example: 0x1 = Thread 0 is skipped.  </td></tr>
<tr>
<td>&ndash;mpi &lt;mpitype&gt; </td><td>Specify the type of the MPI implementation.<br />
<code>likwid-mpirun</code> tries to read the MPI implementation from the <a href="http://modules.sourceforge.net/">modules</a> system.<br />
If not recognized automatically, possible values are <b>intelmpi</b>, <b>openmpi</b> and <b>mvapich2</b>.  </td></tr>
<tr>
<td>&ndash;omp &lt;omptype&gt; </td><td>Specify the type of OpenMP implementation.<br />
<code>likwid-mpirun</code> tries to read the OpenMP implementation using <em>ldd</em> and the <a href="http://modules.sourceforge.net/">modules</a> system.<br />
If not recognized automatically, possible values are <b>intel</b> and <b>gnu</b>  </td></tr>
<tr>
<td>-g, &ndash;group &lt;eventset&gt; </td><td>Use <a class="el" href="likwid-perfctr.html"><code>likwid-perfctr</code></a> to measure performance data for the MPI processes and OpenMP threads.<br />
&lt;eventset&gt; can be either a performance group or a custom event string.<br />
For details see <a class="el" href="likwid-perfctr.html#performance_groups">performance_groups</a>.  </td></tr>
<tr>
<td>-m, &ndash;marker </td><td>Activate the <a class="el" href="likwid-perfctr.html#Marker_API">Marker_API</a> for the measurements with <a class="el" href="likwid-perfctr.html"><code>likwid-perfctr</code></a>.  </td></tr>
<tr>
<td>-O </td><td>Print results in CSV format (conform to <a href="https://tools.ietf.org/html/rfc4180">RFC 4180</a>)  </td></tr>
</table>
<h1>Examples</h1>
<ul>
<li>
<code>likwid-mpirun -np 32 ./a.out</code><br />
 Runs <code>./a.out</code> with 32 MPI processes distributed over the hosts in <code>PBS_NODEFILE</code>  </li>
<li>
<code>likwid-mpirun -nperdomain S:1 ./a.out</code><br />
 Runs <code>./a.out</code> using one MPI process per socket over the hosts in <code>PBS_NODEFILE</code>, <code>LOADL_HOSTFILE</code> or <code>SLURM_HOSTFILE</code>.<br />
The total amount of processes is calculated by &lt;numberOfSocketDomains&gt; * &lt;processCountPerDomain&gt; * &lt;hostsInHostfile&gt;  </li>
<li>
<code>likwid-mpirun &ndash;hostfile host.list -pin S0:2_S1:2 ./a.out</code><br />
 Runs <code>./a.out</code> using two MPI processes per host in <code>host.list</code>.<br />
The first MPI process on each host and its 2 threads are pinned to the first two CPUs on socket <code>S0</code>,<br />
the second MPI process on each host and its 2 threads are pinned to the first two CPUs on socket <code>S1</code>  </li>
<li>
<code>likwid-mpirun -nperdomain S:2 -g MEM ./a.out</code><br />
 Runs <code>./a.out</code> with 2 MPI processes per socket on each host in <code>PBS_NODEFILE</code>, <code>LOADL_HOSTFILE</code> or <code>SLURM_HOSTFILE</code> and measure the <code>MEM</code> performance group<br />
 Only one process per socket measures the Uncore/RAPL counters, the other one(s) only core-local counters.  </li>
</ul>
<p>*/ </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Sat May 21 2016 18:03:00 for LIKWID by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
</body>
</html>
